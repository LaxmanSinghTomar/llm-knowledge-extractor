# Development Notes

## Design Choices

### 1. Why DSPy?

**Rationale**: For production systems handling structured extraction (like legal contracts in DeepLaw), DSPy provides:
- Type-safe signatures with explicit contracts
- Better reliability for structured JSON outputs
- Cleaner separation of prompt engineering from application logic
- Production-ready error handling

**Trade-off**: Slightly more complex setup, but immediate payoff in reliability.

### 2. Tests vs Evals Directory Structure

**Rationale**: Modern AI engineering practice separating concerns:
```
tests/  → Fast, deterministic, CI-ready
evals/  → Slow, probabilistic, quality assessment
```

**Benefits**: Prevents expensive API calls in CI, clear separation of correctness vs quality metrics.

### 3. FastAPI + SQLAlchemy + SQLite

**Rationale**:
- FastAPI: Async-first, automatic OpenAPI docs, type-safe
- SQLAlchemy: Database abstraction, easy migration path
- SQLite: Zero-config prototyping, production-ready schema

**Trade-off**: SQLite is single-writer; production would use PostgreSQL.

### 4. spaCy for Keyword Extraction

**Rationale**: Assignment requires "most frequent nouns" implemented manually (not LLM).
- Uses linguistic features (POS tagging, lemmatization)
- Fast and deterministic
- Demonstrates classical NLP understanding

### 5. uv for Dependency Management

**Rationale**: 10-100x faster than pip/poetry, modern Python tooling, shows ecosystem awareness.

### 6. LLM-Based Confidence Score

**Rationale**: Confidence score is generated by the LLM itself rather than heuristics.

**Why LLM-based over heuristics**:
- **Simpler implementation**: Single source of truth from the model
- **Model awareness**: LLM can assess its own uncertainty about the analysis
- **Consistency**: Confidence matches the same reasoning process that generated other outputs

**Alternative considered**: Heuristic based on text length, keyword count, etc. - rejected for simplicity and because LLM handles most of the analysis work anyway.

---

## Assumptions Made

1. **OpenAI API Access**: Assumes valid API key, GPT-4.1-mini default
2. **English Only**: spaCy model and prompts assume English input
3. **Single-User Context**: No authentication, suitable for prototype
4. **JSON Storage**: Topics/keywords as JSON strings (simple for prototype)
5. **Synchronous Processing**: Acceptable for low-traffic prototype

---

## Current Limitations

### 1. Performance
- **Issue**: Synchronous LLM calls block requests (~1-3s each)
- **Impact**: Poor concurrent request handling
- **Fix**: Implement async LLM calls + background task queues

### 2. Search Capabilities
- **Issue**: Basic SQL LIKE substring matching only
- **Impact**: No semantic similarity (e.g., "AI" won't match "artificial intelligence")
- **Fix**: Add vector embeddings + similarity search (pgvector/Pinecone)

### 3. No Caching
- **Issue**: Identical inputs trigger new LLM calls
- **Impact**: Unnecessary API costs and latency
- **Fix**: Redis-based caching with text hash keys

### 4. Authentication & Authorization
- **Issue**: No API keys, rate limiting, or user isolation
- **Impact**: Not production-ready
- **Fix**: Add JWT auth, API key management, rate limits

### 5. Error Recovery
- **Issue**: No retry logic on LLM failures
- **Impact**: Transient errors cause complete failures
- **Fix**: Exponential backoff retry + circuit breaker

### 6. Monitoring & Observability
- **Issue**: No structured logging, metrics, or tracing
- **Impact**: Hard to debug production issues
- **Fix**: Add structlog, Prometheus metrics, OpenTelemetry

### 7. Cost Management
- **Issue**: No token usage tracking or budget limits
- **Impact**: Uncontrolled API costs
- **Fix**: Per-user cost tracking + budget alerts

---

## How to Improve This System

### Short-term (< 1 week)

1. **Async Processing**
   - Convert to async/await for LLM calls
   - Use asyncio.gather() for concurrent processing

2. **Basic Caching**
   - Add LRU cache or Redis for repeated queries
   - Hash-based lookup for exact matches

3. **Structured Logging**
   - Replace print statements with structured logs
   - Add request IDs for tracing

4. **Request Validation**
   - Max text length limits (10K tokens)
   - Rate limiting per IP
   - Input sanitization

### Medium-term (1-2 weeks)

1. **Vector Search**
   - Add text embeddings for semantic similarity
   - Implement cosine similarity search

2. **Background Queue**
   - Celery or RQ for async processing
   - Job status tracking

3. **Batch Processing**
   - `/analyze/batch` endpoint for multiple texts
   - Parallel processing with rate limits

4. **Authentication**
   - JWT tokens with refresh mechanism
   - API key management

### Long-term (1+ month)

1. **Multi-model Support**
   - Claude, Gemini, local models
   - Model routing based on text type
   - Cost optimization

2. **Advanced Analytics**
   - Quality metrics tracking over time
   - A/B testing for prompts
   - User feedback loops

3. **Domain Customization**
   - Fine-tuned keyword extraction
   - Custom entity recognition
   - Industry-specific sentiment

4. **Scalability**
   - PostgreSQL with replicas
   - Horizontal scaling with load balancer
   - Read/write workload separation

---

## Architecture Evolution

### Current: Prototype
```
FastAPI → DSPy + OpenAI → SQLite
```

### Near-term: MVP
```
FastAPI + Auth → Redis Cache → DSPy → PostgreSQL
                            ↓
                    Background Queue
```

### Production: Scale
```
Load Balancer → FastAPI Cluster → Redis → Vector DB + PostgreSQL
                                        ↓
               Message Queue → Workers → Multi-LLM Backend
                                        ↓
                                 Monitoring
```

---

## Cost Optimization Strategies

1. **Prompt Optimization**: Shorter, focused prompts with lower max_tokens
2. **Caching**: Exact + fuzzy matching for similar inputs
3. **Model Selection**: Open Source LLMs for simple cases, GPT-4.1 for complex
4. **Batch Processing**: Group similar requests, off-peak processing

---

## Security for Production

1. **Input Validation**: Length limits, content filtering, rate limiting
2. **API Security**: JWT auth, API key rotation, CORS configuration
3. **Data Privacy**: Encryption at rest, no logging of user input, GDPR compliance
4. **LLM Security**: Prompt injection protection, output validation, cost limits

---

**Last Updated**: October 1, 2025
